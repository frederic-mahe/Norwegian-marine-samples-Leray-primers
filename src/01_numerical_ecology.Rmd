---
title: " Norwegian Marine Samples COI (#1) "
author: "Frédéric Mahé"
date: '`r format(Sys.time(), "%d %B %Y")`'

output:
  rmarkdown::html_document:
    theme: lumen
    toc: yes
    toc_float: TRUE
    keep_md: yes
    # code_folding: hide
---

```{r setup, include=FALSE}
rm(list = ls()) # remove all objects before starting
knitr::opts_chunk$set(echo = TRUE)
```

***

#### load required packages

```{r packages, message=FALSE}
library(here)
library(tidyverse)
library(vegan)
```


# checks, taxonomic filtering, and subsampling

## variables and functions

```{r}
input <- "FDIR.Curated_LULU_20210729.csv"
title <- "Norwegian marine samples COI NMDS"
rarefied_table <- str_replace(input, ".csv", "_protists_rarefied.csv")
non_protists <- c("Archaeplastida", "Opisthokonta", "Prokaryota")
min_number_of_reads <- 1000
seed <- 123
n_subsamplings <- 100
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00", "#CC79A7")
```

Force `dplyr` to read all the rows of the input table before guessing
the type of each column. Otherwise, the wrong type will be guessed for
some samples (`logical` instead of `double`). A more elegant solution
would be to indicate that all columns starting with `FD01_` to `FD04_`
are samples and should be interpreted as `double`, but that's not yet
possible with `dplyr`.

```{r}
load_raw_occurrence_data <- function(filename){
    here::here("data", filename) %>%
        read_delim(delim = ";",
                   na = c("0", "", "NA"),
                   guess_max = 39000,
                   show_col_types = FALSE)
}
```


## preliminary checks and filtering

here we go!

```{r}
load_raw_occurrence_data(input) -> raw_table
```

how many reads per superkingdom?

```{r}
raw_table %>%
    pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads",
                 values_drop_na = TRUE) %>%
    count(superkingdom_name, wt = reads, name = "reads") %>%
    mutate(percentage = 100 * reads / sum(reads))
```

note the number of unassigned reads (`NA`), or reads assigned to
`Prokaryota` (are these alphaproteobacteria?). The next step is to
eliminate unassigned OTUs and OTUs assigned to plants, animals and
bacteria:

```{r}
raw_table %>%
    filter(! is.na(superkingdom_name) &
           ! superkingdom_name %in% non_protists) %>%
    select(id, starts_with("FD0")) %>%
        pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads",
                 values_drop_na = TRUE) -> protists_table

rm(raw_table)
```

compute the number of reads per sample:

```{r}
protists_table %>%
    count(samples, wt = reads, name = "reads", sort = TRUE) %>%
    filter(reads < min_number_of_reads) %>%
    select(samples) %>%
    pull() -> list_of_small_samples

length(list_of_small_samples) -> number_of_small_samples
```

there are `r prettyNum(number_of_small_samples, scientific=FALSE, big.mark=",")`
samples with less than `r prettyNum(min_number_of_reads, scientific=FALSE, big.mark=",")` reads.

eliminate small samples and make a transposed table in wide format:

```{r}
protists_table %>%
    filter(! samples %in% list_of_small_samples) %>%
    pivot_wider(names_from = "samples",
                values_from = "reads",
                values_fill = 0) -> protists_table_reduced

protists_table_reduced %>%
    select(id) -> OTU_ids

protists_table_reduced %>%
    select(-id) %>%
    t() -> protists_table_transposed
```


## rarefaction (random subsampling)

Randomly subsample the table, so all samples have the same number of
reads. Repeat the process `r n_subsamplings` times to make sure that
the final profile is as close as possible to the initial
distribution. Use a fix seed to make the process 100% repeatable. That
step can take several minutes to run.

```{r}
set.seed(seed)
matrix1 <- vegan::rrarefy(protists_table_transposed, min_number_of_reads)
for (i in 2:n_subsamplings) {
    matrix1 <- matrix1 + vegan::rrarefy(protists_table_transposed, min_number_of_reads)
}

matrix1 / n_subsamplings -> protists_table_transposed_rarefied

rm(i, n_subsamplings, matrix1, list_of_small_samples,
   protists_table_transposed)
```

Prepare to remove empty OTUs from the final rarefied table:

```{r}
. %>%
    pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(reads > 0) %>%
    group_by(id) %>%
    mutate(total = sum(reads),
           spread = n()) %>%
    ungroup() %>%
    pivot_wider(names_from = samples,
                values_from = reads,
                values_fill = 0) %>%
    filter(total > 0) -> remove_empty_OTUs
```

Rebuild and save the newly rarefied OTU table:

```{r}
bind_cols(OTU_ids,
          protists_table_transposed_rarefied %>%
          t() %>%
          as.data.frame() %>%
          as_tibble()) %>%
    remove_empty_OTUs -> protists_table_rarefied

protists_table_rarefied %>%
    write_tsv(file = here::here("data", rarefied_table))
```

How many reads per sample in the final table?

```{r}
protists_table_rarefied %>%
    pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads") %>%
    count(samples, wt = reads, name = "reads") %>%
    summary()

rm(OTU_ids, protists_table, protists_table_rarefied)
```

As expected, there are now
 `r prettyNum(min_number_of_reads, scientific=FALSE, big.mark=",")`
 reads in all samples.


## Alpha diversity

Shannon index **H** (richness + evenness):

```{r}
protists_table_transposed_rarefied %>%
    round() %>%
    vegan::diversity(., index = "shannon") %>%
    as.data.frame() %>%
    rownames_to_column(var = "samples") %>%
    rename(shannon = 2) -> protist_table_shannon

protists_table_transposed_rarefied %>%
    round() %>%
    vegan::diversity(., index = "invsimpson") %>%
    as.data.frame() %>%
    rownames_to_column(var = "samples") %>%
    rename(invsimpson = 2) -> protist_table_invsimpson

protists_table_transposed_rarefied %>%
    round() %>%
    vegan::specnumber(.) %>%
    as.data.frame() %>%
    rownames_to_column(var = "samples") %>%
    rename(specnumber = 2) -> protist_table_specnumber


merge(protist_table_shannon, protist_table_invsimpson) -> shannon_simpson
merge(shannon_simpson, protist_table_specnumber) -> table_shannon_simpson_specnumber
summary(table_shannon_simpson_specnumber)

table_shannon_simpson_specnumber %>%
  filter(., str_detect(samples, "FD01")) -> FD01_sha_inv_spec
summary(FD01_sha_inv_spec)
table_shannon_simpson_specnumber %>%
  filter(., str_detect(samples, "FD02")) -> FD02_sha_inv_spec
summary(FD02_sha_inv_spec)
table_shannon_simpson_specnumber %>%
  filter(., str_detect(samples, "FD03")) -> FD03_sha_inv_spec
summary(FD03_sha_inv_spec)
table_shannon_simpson_specnumber %>%
  filter(., str_detect(samples, "FD04")) -> FD04_sha_inv_spec
summary(FD04_sha_inv_spec)

combined_FD_sha_inv_spec <- rbind(
  mutate(FD01_sha_inv_spec, category = "FD01_samples"),
  mutate(FD02_sha_inv_spec, category = "FD02_samples"),
  mutate(FD03_sha_inv_spec, category = "FD03_samples"),
  mutate(FD04_sha_inv_spec, category = "FD04_samples")
)

ggplot(data = combined_FD_sha_inv_spec,
       aes(x = samples, y = shannon)) + 
  geom_point(aes(color = category)) +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(labels = NULL) +
  theme_bw() +
  facet_wrap(~category, scales = "free_x") +
  xlab("Samples") +
  ylab("Shannon Index")

ggplot(data = combined_FD_sha_inv_spec,
       aes(x = samples, y = invsimpson)) + 
  geom_point(aes(color = category)) +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(labels = NULL) +
  theme_bw() +
  facet_wrap(~category, scales = "free_x") +
  xlab("Samples") +
  ylab("Inverse Simpson Index")

ggplot(data = combined_FD_sha_inv_spec,
       aes(x = samples, y = specnumber)) + 
  geom_col(color = "black", aes(fill = category)) +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(labels = NULL) +
  theme_bw() +
  facet_wrap(~category, scales = "free_x") +
  xlab("Samples") +
  ylab("Number of Species")
```


## NMDS

### local functions

```{r}
. %>%
    vegan::vegdist(., method = "bray") %>%
    vegan::metaMDS(.) -> compute_NMDS_coordinates

. %>%
    vegan::scores(., display = "sites") %>%
    as.data.frame() %>%
    rownames_to_column(var = "samples") %>%
    separate(col = samples,
             into = c("locality", "junk", "sample"),
             sep = "_") -> extract_NMDS_coordinates

. %>%
    round(., digits = 4) %>%
    paste("stress: ", ., sep = "") -> format_stress_annotation
```


### computation

Dissimilarity (Bray-Curtis) and ordination (NMDS):

```{r}
set.seed(seed)

protists_table_transposed_rarefied %>%
    compute_NMDS_coordinates -> occurrences_t.bray.nmds
```


### prepare results

extract data scores and add stress value:

```{r}
occurrences_t.bray.nmds %>%
    extract_NMDS_coordinates -> data.scores

data.scores %>%
    select(NMDS1) %>%
    min() -> x_min

data.scores %>%
    select(NMDS2) %>%
    max() -> y_max

occurrences_t.bray.nmds$stress %>%
    format_stress_annotation -> stress_annotation
```


### plot

```{r}
ggplot(data = data.scores,
       aes(x = NMDS1, y = NMDS2, fill = locality)) +
    scale_fill_manual(values = cbPalette) +
    scale_colour_manual(values = cbPalette) +
    geom_point(size = 6, shape = 21, colour = "black", stroke = 0.5) +
    theme_bw(base_size = 16) +
    ggtitle(title) +
    annotate("text", x = x_min + abs(x_min / 8),
             y = y_max, label = stress_annotation) -> nmds_plot

nmds_plot
```

No obvious structuration.

Add ellipses representing t-distributions (solid lines) and normal
distributions (dashed lines):

```{r}
nmds_plot +
    stat_ellipse(aes(colour = locality), type = "norm", linetype = 2) +
    stat_ellipse(aes(colour = locality), type = "t", linetype = 1)
```

The t-distribution, also known as Student's t-distribution, is a type
of normal distribution used for smaller sample sizes, where the
variance in the data is unknown.


Clean up:

```{r}
rm(data.scores, input, nmds_plot, occurrences_t.bray.nmds,
   stress_annotation, title, x_min, y_max)
```


***

```{r}
sessionInfo()
rm(list = ls())
```
