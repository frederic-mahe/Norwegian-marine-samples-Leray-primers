---
title: " Norwegian Marine Samples COI (#1) "
author: "Frédéric Mahé"
date: '`r format(Sys.time(), "%d %B %Y")`'

output:
  rmarkdown::html_document:
    theme: lumen
    toc: yes
    toc_float: TRUE
    keep_md: yes
    # code_folding: hide
---

```{r setup, include=FALSE}
rm(list = ls()) # remove all objects before starting
knitr::opts_chunk$set(echo = TRUE)
```

***

#### load required packages

```{r packages, message=FALSE}
library(here)
library(tidyverse)
library(vegan)
```


# checks, taxonomic filtering, and subsampling

## variables and functions

```{r}
input <- "FDIR.Curated_LULU_20210729.csv"
title <- "Norwegian marine samples COI NMDS"
rarefied_table <- str_replace(input, ".csv", "_protists_rarefied.csv")
non_protists <- c("Archaeplastida", "Opisthokonta", "Prokaryota")
min_number_of_reads <- 1000
seed <- 123
n_subsamplings <- 100
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#0072B2", "#D55E00", "#CC79A7")
```

Force `dplyr` to read all the rows of the input table before guessing
the type of each column. Otherwise, the wrong type will be guessed for
some samples (`logical` instead of `double`). A more elegant solution
would be to indicate that all columns starting with `FD01_` to `FD04_`
are samples and should be interpreted as `double`, but that's not yet
possible with `dplyr`.

```{r}
load_raw_occurrence_data <- function(filename){
    here::here("data", filename) %>%
        read_delim(delim = ";",
                   na = c("0", "", "NA"),
                   guess_max = Inf,
                   show_col_types = FALSE)
}
```


## preliminary checks and filtering

here we go!

```{r}
load_raw_occurrence_data(input) -> raw_table
```

how many reads per superkingdom?

```{r}
raw_table %>%
    pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads",
                 values_drop_na = TRUE) %>%
    count(superkingdom_name, wt = reads, name = "reads") %>%
    mutate(percentage = 100 * reads / sum(reads))
```

note the number of unassigned reads (`NA`), or reads assigned to
`Prokaryota` (are these alphaproteobacteria?). The next step is to
eliminate unassigned OTUs and OTUs assigned to plants, animals and
bacteria:

```{r}
raw_table %>%
    filter(! is.na(superkingdom_name) &
           ! superkingdom_name %in% non_protists) %>%
    select(id, starts_with("FD0")) %>%
        pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads",
                 values_drop_na = TRUE) -> protists_table

rm(raw_table)
```

compute the number of reads per sample:

```{r}
protists_table %>%
    count(samples, wt = reads, name = "reads", sort = TRUE) %>%
    filter(reads < min_number_of_reads) %>%
    select(samples) %>%
    pull() -> list_of_small_samples

length(list_of_small_samples) -> number_of_small_samples
```

there are `r prettyNum(number_of_small_samples, scientific=FALSE, big.mark=",")`
samples with less than `r prettyNum(min_number_of_reads, scientific=FALSE, big.mark=",")` reads.

eliminate small samples and make a transposed table in wide format:

```{r}
protists_table %>%
    filter(! samples %in% list_of_small_samples) %>%
    pivot_wider(names_from = "samples",
                values_from = "reads",
                values_fill = 0) -> protists_table_reduced

protists_table_reduced %>%
    select(id) -> OTU_ids

protists_table_reduced %>%
    select(-id) %>%
    t() -> protists_table_transposed
```


## rarefaction (random subsampling)

Randomly subsample the table, so all samples have the same number of
reads. Repeat the process `r n_subsamplings` times to make sure that
the final profile is as close as possible to the initial
distribution. Use a fix seed to make the process 100% repeatable. That
step can take several minutes to run.

```{r}
set.seed(seed)
matrix1 <- vegan::rrarefy(protists_table_transposed, min_number_of_reads)
for (i in 2:n_subsamplings) {
    matrix1 <- matrix1 + vegan::rrarefy(protists_table_transposed, min_number_of_reads)
}

matrix1 / n_subsamplings -> protists_table_transposed_rarefied

rm(i, n_subsamplings, matrix1, list_of_small_samples,
   protists_table_transposed)
```

Prepare to remove empty OTUs from the final rarefied table:

```{r}
. %>%
    pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads") %>%
    filter(reads > 0) %>%
    group_by(id) %>%
    mutate(total = sum(reads),
           spread = n()) %>%
    ungroup() %>%
    pivot_wider(names_from = samples,
                values_from = reads,
                values_fill = 0) %>%
    filter(total > 0) -> remove_empty_OTUs
```

Rebuild and save the newly rarefied OTU table:

```{r}
bind_cols(OTU_ids,
          protists_table_transposed_rarefied %>%
          t() %>%
          as.data.frame() %>%
          as_tibble()) %>%
    remove_empty_OTUs -> protists_table_rarefied

protists_table_rarefied %>%
    write_tsv(file = here::here("data", rarefied_table))
```

How many reads per sample in the final table?

```{r}
protists_table_rarefied %>%
    pivot_longer(cols = starts_with("FD0"),
                 names_to = "samples",
                 values_to = "reads") %>%
    count(samples, wt = reads, name = "reads") %>%
    summary()

rm(OTU_ids, protists_table, protists_table_rarefied)
```

As expected, there are now
 `r prettyNum(min_number_of_reads, scientific=FALSE, big.mark=",")`
 reads in all samples.


## NMDS

### computation

rename for readability:

```{r}
occurrences_t <- protists_table_transposed_rarefied
```

Bray-Curtis dissimilarity matrix:

```{r}
occurrences_t.bray <- vegan::vegdist(occurrences_t, method = "bray")
```

NMDS ordination:

```{r}
set.seed(seed)
occurrences_t.bray.nmds <- vegan::metaMDS(occurrences_t.bray)
```


### prepare results

extract data scores and add stress value:

```{r}
stress <- occurrences_t.bray.nmds$stress
samples <- rownames(occurrences_t)
data.scores <- as.data.frame(vegan::scores(occurrences_t.bray.nmds,
                                           display = "sites"))
data.scores$samples <- rownames(data.scores)

x_min <- min(data.scores$NMDS1)
y_max <- max(data.scores$NMDS2)
stress_annotation <- paste("stress: ", round(stress, digits = 4), sep = "")
```

parse sample names:

```{r}
data.scores %>%
    separate(col = samples, into = c("locality", "junk", "sample"), sep = "_") -> d
```


### plot

```{r}
ggplot(data = d,
       aes(x = NMDS1, y = NMDS2, fill = locality)) +
    scale_fill_manual(values = cbPalette) +
    scale_colour_manual(values = cbPalette) +
    geom_point(size = 6, shape = 21, colour = "black", stroke = 0.5) +
    theme_bw(base_size = 16) +
    ggtitle(title) +
    annotate("text", x = x_min + abs(x_min / 8),
             y = y_max, label = stress_annotation) -> nmds_plot

nmds_plot
```

No obvious structuration.

Add ellipses representing t-distributions (solid lines) and normal
distributions (dashed lines):

```{r}
nmds_plot +
    stat_ellipse(aes(colour = locality), type = "norm", linetype = 2) +
    stat_ellipse(aes(colour = locality), type = "t", linetype = 1)
```

The t-distribution, also known as Student's t-distribution, is a type
of normal distribution used for smaller sample sizes, where the
variance in the data is unknown.


Clean up:

```{r}
rm(data.scores, input, nmds_plot,
   occurrences_t, occurrences_t.bray, occurrences_t.bray.nmds,
   samples, stress, stress_annotation, title, useful_metadata, x_min,
   y_max)

ls()
```


***

```{r}
sessionInfo()
rm(list = ls())
```
